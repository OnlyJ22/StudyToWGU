### Section 1: What Are AVL Trees?

#### Introduction to AVL Trees

**AVL Trees** are named after their inventors, **Adelson-Velsky and Landis**.
They are a type of **self-balancing binary search tree (BST)**.

> Unlike regular binary search trees, AVL trees automatically **rebalance** themselves to maintain optimal performance.

---

#### AVL Tree Characteristics

* Each **node** holds **one key**
* Each node has at most **two child nodes**
* The **height difference** between left and right subtrees (called the **balance factor**) must be **-1, 0, or +1**
* Any imbalance triggers a **rotation** to restore balance

---

#### The Balance Factor

The **balance factor** of a node is:

```
balanceFactor = height(left subtree) - height(right subtree)
```

* **Valid balance factors**: -1, 0, 1 → Tree is balanced
* **Invalid** (e.g., ±2) → Tree is unbalanced → requires rotation

**Examples:**

* Tree B → Left height = Right height → Balance Factor = 0 → **Balanced**
* Tree U → Left height = 0, Right height = 2 → Balance Factor = -2 → **Unbalanced**

---

#### Rotations in AVL Trees

To fix imbalance, AVL trees perform **rotations** using one node as the **pivot**.
Rotations ensure the balance factor of each node is restored to within \[-1, 1].

---

#### Single Rotations

**1. Left Rotation (RR imbalance)**

* Used when **right subtree is too tall**
* Pivot moves **left**

**2. Right Rotation (LL imbalance)**

* Used when **left subtree is too tall**
* Pivot moves **right**

---

#### Double Rotations (Complex Cases)

In some cases, a **single rotation isn’t enough**, and two rotations are needed.

**Example:**

Nodes inserted in this order:
`10 → 8 → 15 → 13 → 20 → 18`

Result: Unbalanced at node `10` due to right-heavy subtree.
Fix: **Left Rotation at 15** (pivot), tree becomes **balanced**

---

#### Insertion in AVL Trees

The **insert** operation may cause an imbalance. After insertion:

1. Traverse up the **path of insertion**
2. Check the **balance factor** of each node
3. Apply **rotations** as needed

**Example:**

* Insert node `91` causes imbalance
* Tree is rebalanced by **rotating at node 85**

---

#### Deletion in AVL Trees

**Deleting a node** can also unbalance the tree.

1. Remove the target node
2. Traverse upward from deletion path
3. **Rotate** as needed to restore balance

**Example:**

* Delete node `2` → Tree becomes unbalanced
* Apply **left rotation** → Tree returns to balanced state

---

#### Applications and Use Cases

* AVL trees are ideal for situations involving **frequent lookups**
* Not ideal for environments with **heavy insertions/deletions**
* Use cases include:

  * **Databases**
  * **Indexing**
  * **File systems**
  * **Real-time systems** needing consistent lookup times

---

#### Lesson Summary

* An **AVL Tree** is a self-balancing **binary search tree**
* It maintains balance by ensuring the **balance factor** of each node is between **-1 and 1**
* **Insertions and deletions** may unbalance the tree
* The tree uses **rotations** to restore balance
* AVL trees are best used where **lookups are more frequent** than inserts or deletes

AVL Trees provide efficient, consistent performance for sorted data operations where tree balance is crucial.

### Section 2: What Are Search Trees?

---

**🔍 Introduction**
Search trees are binary (two-way) or non-binary (multi-way) structures used in algorithms to execute operations on an ordered data set. In this lesson, we’ll explore three major types of search trees.

---

**🌳 Multiway Search Trees**

Multiway Search Trees allow each node to store **multiple child nodes (more than two)**. These differ from binary search trees, which allow only two. Key characteristics include:

* Nodes may carry multiple keys.
* Each node may have `N` children.
* Each node maintains `N - 1` search keys.
* All leaf nodes are maintained at the same level.

**Operations:**

* **Search**: Begins at the root and traverses nodes to locate the key.
* **Insert**: Ensures a key does not exist, then adds it to the appropriate node.
* **Delete**: Locates and removes a key from the tree.

---

**🌲 2-3-4 Trees**

A **2-3-4 tree** is a type of Multiway Search Tree where each node can hold **2, 3, or 4 child nodes** and up to **three key values**. These trees are **self-balancing** — they reorganize themselves to maintain structure after inserts or deletes.

**Characteristics:**

* Nodes can hold 2, 3, or 4 children.
* Nodes contain up to 3 keys (`N - 1` rule).
* All leaf nodes remain on the same level.

**Operations:**

* **Search**: A sequential search is performed within each node.
* **Insert**: The tree ensures no duplicates and adds keys while preserving balance. If a node overflows, it is split, and its middle key is promoted.
* **Delete**: Removes a key and rebalances the tree as needed.

**Example:**

* Inserting key `151` may cause a node to overflow. This requires splitting and possibly creating a new root to preserve 2-3-4 properties.

---

**🟥⬛ Red-Black Trees**

Red-Black Trees are **binary search trees with color-coded nodes**. Each node is either red or black and follows rules to preserve balance.

**Rules:**

* Every node is red or black.
* The root and leaves (null children) are always black.
* A red node cannot have a red child.
* Every path from a node to its descendants contains the same number of black nodes.

**Operations:**

* **Search**: Follows standard binary search logic.
* **Insert**:

  * All new nodes are inserted as red.
  * If insertion violates rules, **color changes** or **rotations** are applied to fix the imbalance.
* **Delete**:

  * The deleted node is replaced.
  * If black-height property is violated, rotations and recoloring are performed to fix the structure.

**Scenarios:**

* **Case 1**: Root insertion — recolor black.
* **Case 2**: Red uncle — recolor parent and uncle.
* **Case 3**: Black uncle — rotate and recolor parent/grandparent as needed.

---

**📌 Lesson Summary**

| Tree Type      | Child Nodes | Self-Balancing | Special Properties                   |
| -------------- | ----------- | -------------- | ------------------------------------ |
| Multiway Tree  | 2 or more   | No             | All leaves on same level             |
| 2-3-4 Tree     | 2, 3, or 4  | Yes            | Maintains balance by splitting nodes |
| Red-Black Tree | Max 2       | Yes            | Color-coded with black-height rules  |

Search trees are used to efficiently search, insert, and delete data in ordered sets. Each variant has specific advantages based on the required operations and performance constraints.


### Section 3: Splay Trees

---

**🔍 What Is a Splay Tree?**

A **splay tree** is a type of **binary search tree (BST)**, where the tree self-adjusts during operations by moving frequently accessed elements toward the top. This optimizes access time for those elements.

In a typical BST, the time to access elements can grow with the depth of the tree. Splay trees improve performance by **rotating accessed nodes to the root** using specialized tree rotations.

---

**🌿 Splay Tree Operations**

Splay trees perform standard BST operations like `insert`, `find`, and `remove`, but also **restructure themselves** after every access using **splay operations**.

The three main splay operations are:

* **Zig**
* **Zig-Zag**
* **Zig-Zig**

Each operation involves **up to two tree rotations**, and they all result in the accessed node being moved closer to the root.

---

**🔁 Zig Operation**

Occurs when the node to splay is a **child of the root**. Only **one rotation** is needed.

```
Before:      After:
   10           15
     \    =>   /
     15       10
```

---

**🔁 Zig-Zag Operation**

Occurs when the node is the **right child of a left child** or **left child of a right child**. Requires **two rotations** in opposite directions.

```
Before:        After:
   10             15
  /               / \
 8               8  10
   \
    15
```

---

**🔁 Zig-Zig Operation**

Occurs when the node is the **left child of a left child** or **right child of a right child**. Requires **two rotations in the same direction**.

```
Before:       After:
   20           15
    \          /
     18  =>   10
       \
        15
```

---

**📈 Performance**

* **Time Complexity**: Average **O(log n)** per operation
* **Amortized Analysis**: Some operations may take longer, but over time they balance out
* **Best For**: Workloads with **frequent re-access** to a small subset of data

Example:
Accessing element `15` often? The splay tree ensures it stays near the root, reducing lookup time for future accesses.

---

**💻 Java Implementation (Snippet)**

Here's a basic outline of splay tree logic in Java:

```java
class Node {
    int value;
    Node left, right, parent;
    Node(int value) {
        this.value = value;
    }
}
```

**Rotate Left:**

```java
private void rotateLeft(Node node) {
    Node p = node.parent;
    p.right = node.left;
    if (node.left != null) node.left.parent = p;
    node.left = p;
    updateParent(node, p);
}
```

**Rotate Right:**

```java
private void rotateRight(Node node) {
    Node p = node.parent;
    p.left = node.right;
    if (node.right != null) node.right.parent = p;
    node.right = p;
    updateParent(node, p);
}
```

**Zig-Zag Example:**

```java
private void zigZag(Node node) {
    if (node == node.parent.left) {
        rotateRight(node);
        rotateLeft(node);
    } else {
        rotateLeft(node);
        rotateRight(node);
    }
}
```

---

**🧠 Lesson Summary**

* A **splay tree** is a self-adjusting binary search tree.
* It brings **recently accessed nodes to the root** using **zig, zig-zag, or zig-zig** operations.
* This improves performance for data that is **accessed repeatedly**.
* Searching is based on a **divide and conquer** approach.
* The time complexity is **O(log n)** on average, making it efficient for many practical use cases.


### Section 4: What Are Search Algorithms?
---

**🔍 Introduction to Search Algorithms**

A **search algorithm** takes input in the form of **search keys** or **strings** and uses procedures to find relevant data in files, directories, databases, or web content. Think of it like bringing a fabric swatch to a store and asking someone to locate a match—it depends on how the store is arranged, how much stock there is, and how informed the person helping you is.

---

**📏 Big O Notation and Algorithm Efficiency**

**Big O Notation** is used to express an algorithm’s **time complexity**—its rate of growth as data input increases. It typically represents the **worst-case** performance.

**Common Big O Types:**

| Growth Type | Big O Notation |
| ----------- | -------------- |
| Linear      | O(n)           |
| Logarithmic | O(log n)       |
| Quadratic   | O(n²)          |
| Exponential | O(cⁿ)          |

In general, **logarithmic growth (O(log n))** is considered fast and efficient, while **linear (O(n))** and **exponential** are slower and more resource-intensive.

---

**🌳 Binary Search Tree (BST)**

A **BST** organizes data hierarchically with a root and two branches. Ideally, it supports efficient searching.

* **Best Case**: O(log n) when balanced
* **Worst Case**: O(n) if unbalanced (degrades to a linked list)

**Strengths:**

* Efficient for add, delete, and search operations if balanced
* Performance improves as data increases due to logarithmic access pattern

**Weaknesses:**

* Poor performance when unbalanced
* Easily degenerates without maintenance

---

**⚖️ AVL Trees**

An **AVL Tree** is a **self-balancing BST** where no child subtree differs in height by more than one. Rotations are applied as needed.

**Strengths:**

* Maintains balance, ensuring O(log n) performance
* Efficient even with large datasets

**Weaknesses:**

* Complex to implement and maintain
* Additional memory and processing overhead due to rebalancing

---

**🔄 Splay Trees**

**Splay Trees** adjust themselves during access operations, moving frequently accessed elements to the root using rotations (zig, zig-zag, zig-zig).

**Strengths:**

* Improves future lookup times for frequently accessed elements
* Dynamic shape adapts to usage

**Weaknesses:**

* Poorer performance (O(n)) for short or unbalanced sequences
* Variable structure adds complexity

---

**🟥⬛ Red-Black Trees**

A **Red-Black Tree** is a BST with nodes colored **red or black** to enforce balance rules.

**Strengths:**

* Guaranteed O(log n) performance
* Efficient for frequent insertion/deletion operations
* Less strict balancing than AVL = better insertion time

**Weaknesses:**

* Complex logic and implementation
* Locking mechanisms (for concurrency) can slow access

---

**🌐 Multiway Trees (m-way Trees)**

An **m-way Tree** is a generalization of BST where a node can have **more than two children**. Used in scenarios with large datasets or disk-based storage.

**Complexity**: O(log₂ M logM N), where N is the number of elements

**Strengths:**

* Low height = fewer disk accesses
* Handles large data volumes well

**Weaknesses:**

* Can be poorly balanced
* Lower space utilization

---

**🧩 2-3-4 Trees**

A **2-3-4 Tree** is a specific type of Multiway Tree with **2, 3, or 4 children per node**. It is **always balanced**.

**Strengths:**

* Guaranteed O(log n) performance
* Height is constrained, making search efficient

**Weaknesses:**

* More complex node structure
* Often replaced with Red-Black Trees for simplicity

---

**📌 Lesson Summary**

Search algorithms are used to access and manipulate data efficiently. The **Binary Search Tree (BST)** is the most basic form, while **AVL**, **Splay**, and **Red-Black Trees** add self-balancing and structural enhancements. **Multiway** and **2-3-4 Trees** are used when nodes require more than two children and are especially effective for larger datasets.

**Big O Notation** is essential to analyze these structures:

* **Balanced trees** perform best, often at **O(log n)**
* **Unbalanced trees** can degrade to **O(n)**
* **Choosing the right algorithm depends on data structure, frequency of access, and operational complexity**


### Section 5: Primality Testing Algorithms

Primality Testing Algorithms are used to determine if a number is prime. There are two main categories:

* **Deterministic algorithms**: definitively identify whether a number is prime.
* **Probabilistic algorithms**: provide a likely prediction, especially useful with large numbers in cryptography.

---

#### Deterministic Methods

#### Sieve of Eratosthenes

Finds all prime numbers up to a given number `n`.

```java
import java.util.Scanner;
public class Main {
  public static void main(String[] args) {
    System.out.println("Enter a Number: ");
    Scanner sc = new Scanner(System.in);
    int n = sc.nextInt();
    for(int i = 1; i <= n; i++){
      boolean isPrime = true;
      for(int j = i-1; j >=2; j--){
        if(i % j == 0){
          isPrime = false;
          break;
        }
      }
      if(isPrime)
        System.out.print(i+" ");
    }
  }
}
```

---

#### Search Up to Square Root

Instead of checking all numbers, loop only to the square root of `n`.

```java
import java.lang.Math;
public class Main {
  public static void main(String[] args) {
    int n = 23;
    int flag = 1;
    double squareroot = Math.sqrt(n);
    for(int i = 2; i < squareroot; i++) {
      if(n % i == 0) {
        flag = 0;
        break;
      }
    }
    if(flag == 1) {
      System.out.println(n + " is a prime number");
    } else {
      System.out.println(n + " is not a prime number");
    }
  }
}
```

---

#### Probabilistic Methods

#### Fermat’s Little Theorem

If `p` is prime, then for any integer `a`, `a^(p-1) ≡ 1 (mod p)`.

```java
import java.io.*;
import java.math.*;
public class Main {
  static int power(int a,int n, int p) {
    int res = 1;
    a = a % p;
    while (n > 0) {
      if ((n & 1) == 1)
        res = (res * a) % p;
      n = n >> 1;
      a = (a * a) % p;
    }
    return res;
  }

  static boolean isPrime(int n, int k) {
    if (n <= 1 || n == 4) return false;
    if (n <= 3) return true;
    while (k > 0) {
      int a = 2 + (int)(Math.random() % (n - 4));
      if (power(a, n - 1, n) != 1)
        return false;
      k--;
    }
    return true;
  }

  public static void main(String args[]) {
    int k = 131414059;
    System.out.println("Probability of Prime for k = 11 = " + isPrime(11, k));
    System.out.println("Probability of Prime for k = 15 = " + isPrime(15, k));
    System.out.println("Result of k modulo 2: " + k % 2);
  }
}
```

---

#### Miller-Rabin Primality Test

Improves on Fermat's by reducing false positives.

```java
import java.io.*;
import java.math.*;
class Main {
  static int power(int x, int y, int p) {
    int res = 1;
    x = x % p;
    while (y > 0) {
      if ((y & 1) == 1)
        res = (res * x) % p;
      y = y / 2;
      x = (x * x) % p;
    }
    return res;
  }

  static boolean MillerTest(int d, int n) {
    int a = 2 + (int)(Math.random() % (n - 4));
    int x = power(a, d, n);
    if (x == 1 || x == n - 1)
      return true;
    while (d != n - 1) {
      x = (x * x) % n;
      d *= 2;
      if (x == 1) return false;
      if (x == n - 1) return true;
    }
    return false;
  }

  static boolean isPrime(int n, int k) {
    if (n <= 1 || n == 4) return false;
    if (n <= 3) return true;
    int d = n - 1;
    while (d % 2 == 0)
      d /= 2;
    for (int i = 0; i < k; i++)
      if (!MillerTest(d, n))
        return false;
    return true;
  }

  public static void main(String args[]) {
    int k = 4;
    System.out.println("All primes smaller than 1000: ");
    for (int n = 1; n < 1000; n++)
      if (isPrime(n, k))
        System.out.print(n + " ");
  }
}
```

---

#### Hash Functions & Cryptography

* Primality testing is essential in cryptographic systems like RSA.
* Prime numbers are used in generating public and private keys.
* Deterministic and probabilistic tests help verify large primes efficiently.

---

#### Lesson Summary

* **Primality Testing Algorithms** determine if a number is prime.
* **Deterministic** methods: Sieve of Eratosthenes, square root division.
* **Probabilistic** methods: Fermat’s Little Theorem, Miller-Rabin Test.
* Applications include **RSA encryption**, hashing, and security systems.
