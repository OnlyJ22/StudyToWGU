
### Section 1: Text as a Data Structure

#### What Is Text as a Data Structure?

When you see the word **STOP** on a red octagon, do you think of it as one word, or as a sequence of individual letters: `'S'`, `'T'`, `'O'`, `'P'`?

In Java, text can be treated both as a **single unit** (a `String` object) or as a **collection of characters** (a `char[]` array). This means that **text in Java is a data structure** — and you can choose how to interact with it.

> Think of text like a **Lego model**: you can treat it as one assembled object, or take it apart into individual bricks (characters) to rearrange.

---

#### String vs. Character Array

**Example — String Object**

```java
String stopSign = "Stop";
```

**Example — Character Array**

```java
char[] stopSign2 = {'S', 'T', 'O', 'P'};
```

Both forms represent the same text — but they behave **very differently**.

---

#### Strings Are Immutable!

Unlike in C or C++, Java **Strings are immutable**. This means once a `String` is created, it **cannot be changed**.

You might think string methods like `replace()` or `toUpperCase()` change the original — but they actually create a **new** `String` object. The original stays intact.

**Example — String Assignment**

```java
String s1 = "STOP";
String s2 = s1;
s1 = "STAP";
System.out.println(s2);
```

**Output:**

```
STOP
```

Even though `s1` changed, `s2` kept the original value. Why? Because **each String is its own object**.

---

#### Convert a String to a Character Array

To manipulate individual characters, you need to convert the `String` into a `char[]` using the `toCharArray()` method.

**Example — Convert & Loop**

```java
String sign = "STOP";
// convert to char array
char[] newSign = sign.toCharArray();
// cycle through chars
for (char c : newSign) {
    System.out.println(c);
}
System.out.println(sign);
```

> This prints each character separately — and shows that the original String remains untouched.

**Why?** Because character arrays are **mutable** — unlike Strings, you can change individual elements.

**Example — Modify Character Array**

```java
char[] charArray = {'S', 'T', 'O', 'P'};
charArray[2] = '!';
for (char c : charArray) {
    System.out.println(c);
}
```

**Output:**

```
S  
T  
!  
P
```

---

#### Convert a Character Array to a String

If you want to take a character array and turn it into a `String` to use powerful string methods, just pass it into the `String` constructor.

**Example — Convert to String**

```java
char[] charArray = {'S', 'T', 'O', 'P'};
String newArray = new String(charArray);
System.out.println(newArray);
```

This lets you go **both ways**: from `String` to `char[]`, and back.

---

#### StringBuilder: Mutable Text Objects

Strings are immutable — but what if you want to build or modify strings dynamically?

Java offers the **`StringBuilder`** class for this. It's a **mutable** alternative that supports many methods:

* `append(text)` — adds text to the end
* `insert(index, text)` — inserts text at a given index
* `replace(start, end, text)` — replaces characters from start to end
* `delete(start, end)` — deletes characters in a range
* `reverse()` — reverses the string

---

#### Example — StringBuilder in Action

```java
public class Strings {
    public static void main(String[] args) {
        StringBuilder s1 = new StringBuilder("STO");
        System.out.println(s1);
        
        // append the P
        s1.append("P");
        System.out.println(s1);
        
        // insert an exclamation point
        s1.insert(0, "!");
        System.out.println(s1);
        
        // reverse, reverse!
        s1.reverse();
        System.out.println(s1);
    }
}
```

**Output:**

```
STO  
STOP  
!STOP  
POTS!
```

> Unlike Strings, these changes happen **in-place**. You are actually modifying the same object.

---

#### Lesson Summary

* In Java, **text is a data structure** — represented as a `String` or a `char[]`.
* A `String` is **immutable** — any changes create a new object.
* A `char[]` is **mutable** — its elements can be changed directly.
* Use `toCharArray()` to convert from `String` → `char[]`
* Use `new String(charArray)` to go from `char[]` → `String`
* For **modifying text**, use the **`StringBuilder`** class.

  * It allows in-place edits like append, insert, replace, delete, and reverse.

> Mastering text structures is key to **powerful string manipulation** in Java!


### Section 2: String Searching Algorithms

#### What Are String Searching Algorithms?

Every time you type a word or phrase into a **search engine**, you're triggering a string search. These algorithms try to find whether your **pattern** (the search term) exists in a larger **text** (like a webpage or document).

Java and many other languages use **string searching algorithms** to compare and locate substrings within larger strings. Each algorithm varies in its **efficiency**, **speed**, and **complexity**.

> Think of string searching as finding a **needle in a haystack** — different algorithms have smarter or faster ways of doing it.

---

#### Brute Force Algorithm

The **Brute Force** algorithm is the most basic method of string searching. It checks every possible position in the text to find a match.

It answers:

* Is a given pattern `P` a **substring** of text `S`?
* If yes, **where** does it occur (index `i`)?

**Terminology**:

* `S` — the full string
* `P` — the pattern to search
* `n` — length of `S`
* `m` — length of `P`
* Condition: `m ≤ n`

**Example**:

```
S: Peter Piper picked a peck of pickled peppers  
P: pep
```

Each character of `P` is matched to `S`. The number of comparisons per iteration is up to `m`.

**Pseudocode — Brute Force Search**

```java
for i = 0 to n - m {
    j = 0
    while j < m and P[j] == S[i + j] {
        j = j + 1
    }
    if j == m return i
}
return -1
```

> Each mismatch results in the pattern being shifted by one character — no optimization is used.

**Worst Case Time Complexity**:
`O(mn)` — especially if the match is near the **end** of the string.
**Total Comparisons**: `m × (n - m + 1)`

---

#### Boyer-Moore Algorithm

The **Boyer-Moore** algorithm is more efficient. It skips over sections of the string using smart rules — especially helpful for large texts.

It still answers:

* Is pattern `P` found in string `S`?

**Key Concepts**:

1. **Bad Character Rule**:

   * If a mismatch occurs, the pattern is **shifted** past the mismatched character if that character **does not exist** in the pattern.
   * If the character **does exist**, the pattern is shifted so that it aligns with its last occurrence.

**Scenarios**:

* **Mismatch becomes a match** — the pattern shifts to realign with a possible match.
* **Pattern skips irrelevant characters** — reducing unnecessary comparisons.

> The Boyer-Moore algorithm **jumps ahead**, unlike brute force which checks every step.

**Worst Case Time Complexity**:
`O(mn)` — happens when pattern and string contain repeated characters.

**Example**:

```
P: ababababa  
S: ababababababababababa
```

Even with cleverness, in some edge cases it may still behave like brute force.

---

#### Knuth-Morris-Pratt Algorithm (KMP)

The **KMP algorithm** improves on both previous methods by ensuring that the pattern is never re-compared unnecessarily.

**Time Complexity**:
`O(m + n)` — much faster in the worst case.

**How It Works**:

* Preprocess the pattern to create an **LPS (Longest Proper Prefix)** array.
* This array lets the algorithm **reuse previous matches**.

**Terminology**:

* `S` — full string
* `P` — pattern
* `lps[]` — stores longest prefix that is also a suffix
* `n` — length of `S`
* `m` — length of `P`

> The LPS array prevents **going backward** during mismatches.

---

#### Building the LPS Array

The **LPS array** is key to the KMP algorithm. It helps track the length of the **longest prefix which is also a suffix** up to a given point.

**Example**:

```
S : A B X D A B A B X A B  
P : A B X A B
```

At mismatch (e.g., D ≠ A), we avoid rechecking from the start. Instead, we jump to where a **prefix match** may continue, based on LPS.

**Pseudocode — Compute LPS Array**

```java
ComputeLps(r)
m = length of pattern p
r[1] = 0
k = 0

for q = 2 to m {
    while k > 0 and p[k + 1] ≠ p[q] {
        k = r[k]
    }
    if p[k + 1] == p[q] {
        k = k + 1
    }
    r[q] = k
}
return r
```

---

#### Pseudocode — KMP Matcher

```java
KMP_Matcher
n = length of S
m = length of P
q = 0

for i = 1 to n {
    while q > 0 and p[q + 1] ≠ S[i] {
        q = r[q]
    }
    if p[q + 1] == S[i] {
        q = q + 1
    }
    if q == m {
        print "Pattern occurs with shift", i - m
        q = r[q]
    }
}
```

> Each comparison reuses previously matched characters, so we **never re-check** from scratch.

---

#### Lesson Summary

* **Brute Force**

  * Easiest to implement
  * Time complexity: `O(mn)`
  * No optimization — checks every character

* **Boyer-Moore**

  * Smarter than brute force
  * Uses **bad character rule** to skip comparisons
  * Best case: `O(n)`
  * Worst case: `O(mn)`

* **KMP Algorithm**

  * Most efficient in worst case
  * Time complexity: `O(m + n)`
  * Uses **LPS array** to minimize repeated work
  * Harder to implement but ideal for large-scale pattern matching

> The KMP algorithm shines when working with **repetitive data or large datasets**. Boyer-Moore is a popular practical choice, and brute force is best for learning or small datasets.
---

### Section 3: Introduction to the Trie Data Structure

#### What Is a Trie?

A **Trie** (pronounced *"try"*) is a **tree-like data structure** used to efficiently store and search strings. It is particularly useful when working with **prefix-based searches** such as autocomplete, dictionary lookups, and IP routing.

The word **"trie"** comes from the word **"retrieval"**, reflecting its main purpose: **retrieving string-based data quickly**.

> Think of a Trie as a **map of letters** — where each path from root to leaf forms a word.

---

#### Understanding the Structure

Each node in a Trie represents a **single character** and links to its **child nodes**, which represent the next characters in possible words.

**Example — Word Traversal**

To find the word `"CUP"`:

* Start at the root node
* Traverse to `'C'`, then `'U'`, then `'P'`
* Each step moves through a node corresponding to a character

This can also be seen as:
`C → CU → CUP`

---

#### Implementing Trie Operators

To use a Trie, we start by creating a **TNode** class that contains children, accessors, and mutators for its internal structure.

**Example — Creating the Root**

```java
TNode myTree = new TNode();
```

This `myTree` object becomes the **root node** of the trie.

---

#### Adding a String to a Trie

To insert a word into a trie:

1. Convert the string into a character array
2. For each character, move through existing nodes or create new ones
3. Avoid inserting null characters

**Example — `add()` Method**

```java
public void add(String theWord) {
    TNode myNode = myTree;
    for (char theChar : theWord.toCharArray()) {
        TNode childNode = myNode.subNode(theChar);
        if (childNode != null) {
            myNode = childNode;
        } else {
            childNode = new TNode(theChar);
            myNode.nodeList.add(childNode);
            myNode = myNode.subNode(theChar);
        }
    }
}
```

> This method adds new paths to the Trie while preserving existing ones.

---

#### Searching a Trie

To **search for a string**, simply walk through the trie one character at a time using `subNode()` to find each child node.

**Example — Search Operation**

```java
TNode myNode = myTree;
for (char theChar : stringToFind.toCharArray()) {
    myNode = myNode.subNode(theChar);
}
```

If all characters match nodes, the word exists. If any character is missing, the word is not found.

---

#### Advanced Trie Concepts

So far, we’ve looked at a **standard trie**. But there are other types, like **compressed tries**, which are more memory efficient.

**Standard Tries**:

* Store one character per node
* Can be memory-heavy for large datasets with many words sharing prefixes

**Compressed Tries**:

* Compress consecutive single-child nodes into one node
* Useful for **space efficiency** and **faster lookups**
* Often used in **indexing and large-scale text processing**

---

#### Visual Comparison

A **standard trie** might store:

```
C → A → T  
C → A → R  
```

While a **compressed trie** would store:

```
C → AR  
C → AT
```

> Compressed tries **reduce redundant nodes** by merging common paths.

---

#### Lesson Summary

* A **Trie** is a digital tree used to **store and retrieve strings**.
* Each node corresponds to a **character**, and paths through the tree represent **words**.
* **Standard tries** use one character per node.
* **Compressed tries** reduce memory usage by collapsing chains of single-child nodes.
* Tries are not always common in typical Java programming, but are **very efficient** for tasks like prefix matching, autocomplete, and lexicon management.

> Tries combine the **speed of arrays** with the **hierarchy of trees** — making them a powerful tool for string-based operations.
---

### Section 4: Greedy Algorithm

#### What Is a Greedy Algorithm?

A **Greedy Algorithm** is a problem-solving approach that selects the **best available option at each step** without considering the **global optimal solution**. Like a goldfish chasing the biggest crumb it can immediately see, a greedy algorithm always picks what seems best *right now* — not necessarily what's best in the long run.

> Think of a greedy algorithm as **short-sighted but quick**: It acts fast, but sometimes misses a better overall path.

---

#### Greedy Algorithm Example — Max Sum Path

Imagine the goal is to **find the largest sum** in a grid. A greedy algorithm selects the **largest number at each step**.

**Example Path**:

```
Choice between: 3 and 24 → picks 24  
Selected path: 6 → 24 → 27  
Total: 57
```

But the **best path** might actually be:

```
6 → 3 → 88  
Total: 97
```

> A greedy algorithm **doesn’t backtrack** or evaluate all paths. It simply goes for what looks best in the moment.

---

#### Huffman’s Code — A Greedy Algorithm in Action

One powerful use of greedy logic is in **Huffman Coding**, a **data compression** method.

In Huffman Coding, characters are encoded using **shorter bit strings** for **frequent characters** and **longer bit strings** for **rare ones**. This reduces the overall size of the data.

---

#### Fixed-Length vs Variable-Length Coding

In **fixed-length coding**, all characters use the same number of bits — even if some characters appear more often. This wastes space.

> Imagine packing gifts of all sizes into **identical large boxes** — small gifts leave a lot of unused space.

In **variable-length coding**, frequent characters get **small boxes** (short codes), while rare ones get **larger boxes** (longer codes), optimizing space.

---

#### Why Is Huffman’s Code Greedy?

Huffman coding is greedy because:

* It **assigns codes immediately** based on **local frequency decisions**
* At every step, it **combines the least frequent characters**, ensuring minimum total weight at that point
* It does **not wait** to evaluate all possibilities — it builds the best **partial solution** at each step

> Huffman’s algorithm builds an optimal solution piece-by-piece, just like a greedy algorithm would.

---

#### Huffman’s Code — Binary Tree Structure

Huffman coding creates a **binary tree** for compression:

* **Root node** is at the top
* Nodes represent **frequencies**
* Left and right branches form **binary codes**
* The tree is used for **encoding** and **decoding** data

---

#### Building a Huffman Tree — Step-by-Step

**Step 1**:

* Sort frequencies in ascending order
* Combine the two lowest values
* Create a **parent node** with their sum
* Example: 5 + 6 = **11**

**Step 2**:

* Remove 5 and 6 from the list
* Insert the new node (11)
* Sort again and repeat: 10 + 11 = **21**

**Step 3**:

* Remove 10 and 11
* Insert 21
* Continue: 20 + 21 = **41**

**Step 4**:

* Only one node remains — **41**
* This becomes the **root** of the Huffman Tree

> Each step makes a **locally optimal choice** — the essence of the greedy approach.

---

#### Lesson Summary

* A **greedy algorithm** chooses the best local option at every step — without considering the whole problem.
* **Huffman Coding** is a **greedy data compression** algorithm that assigns short codes to frequent characters and longer codes to rare ones.
* **Fixed-length encoding** is wasteful for frequent characters. **Variable-length encoding** optimizes space.
* Huffman coding builds a **binary tree** by:

  1. Sorting by frequency
  2. Combining the two smallest frequencies
  3. Repeating until one node remains (the root)
* Huffman’s method is **greedy** because it chooses the best pairing at each step — building an efficient result without exhaustive searching.

> Greedy algorithms may not always find the global optimum — but in cases like Huffman Coding, they **do**!

---
